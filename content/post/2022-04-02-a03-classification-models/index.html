---
title: A03 Classification Models
author: ''
date: '2022-04-02'
slug: a03-classification-models
categories: []
tags: []
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>###Load libraries</p>
<pre class="r"><code>library(ggplot2)
library(dplyr)</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## -- Attaching packages --------------------------------------- tidyverse 1.3.1 --</code></pre>
<pre><code>## v tibble  3.1.6     v purrr   0.3.4
## v tidyr   1.2.0     v stringr 1.4.0
## v readr   2.1.2     v forcats 0.5.1</code></pre>
<pre><code>## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<p>###Import the data</p>
<pre class="r"><code>train &lt;- read.csv(&#39;https://raw.githubusercontent.com/rkavalakatt/website_delete/main/content/post/2022-04-02-a03-classification-models/train.csv&#39;)
test &lt;- read.csv(&#39;https://raw.githubusercontent.com/rkavalakatt/website_delete/main/content/post/2022-04-02-a03-classification-models/test.csv&#39;)

head(train)</code></pre>
<pre><code>##   PassengerId Survived Pclass
## 1           1        0      3
## 2           2        1      1
## 3           3        1      3
## 4           4        1      1
## 5           5        0      3
## 6           6        0      3
##                                                  Name    Sex Age SibSp Parch
## 1                             Braund, Mr. Owen Harris   male  22     1     0
## 2 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female  38     1     0
## 3                              Heikkinen, Miss. Laina female  26     0     0
## 4        Futrelle, Mrs. Jacques Heath (Lily May Peel) female  35     1     0
## 5                            Allen, Mr. William Henry   male  35     0     0
## 6                                    Moran, Mr. James   male  NA     0     0
##             Ticket    Fare Cabin Embarked
## 1        A/5 21171  7.2500              S
## 2         PC 17599 71.2833   C85        C
## 3 STON/O2. 3101282  7.9250              S
## 4           113803 53.1000  C123        S
## 5           373450  8.0500              S
## 6           330877  8.4583              Q</code></pre>
<pre class="r"><code>head(test)</code></pre>
<pre><code>##   PassengerId Pclass                                         Name    Sex  Age
## 1         892      3                             Kelly, Mr. James   male 34.5
## 2         893      3             Wilkes, Mrs. James (Ellen Needs) female 47.0
## 3         894      2                    Myles, Mr. Thomas Francis   male 62.0
## 4         895      3                             Wirz, Mr. Albert   male 27.0
## 5         896      3 Hirvonen, Mrs. Alexander (Helga E Lindqvist) female 22.0
## 6         897      3                   Svensson, Mr. Johan Cervin   male 14.0
##   SibSp Parch  Ticket    Fare Cabin Embarked
## 1     0     0  330911  7.8292              Q
## 2     1     0  363272  7.0000              S
## 3     0     0  240276  9.6875              Q
## 4     0     0  315154  8.6625              S
## 5     1     1 3101298 12.2875              S
## 6     0     0    7538  9.2250              S</code></pre>
<pre class="r"><code>attach(train)</code></pre>
<p>###Find the number of NAs in each column</p>
<pre class="r"><code>colSums(is.na(train))</code></pre>
<pre><code>## PassengerId    Survived      Pclass        Name         Sex         Age 
##           0           0           0           0           0         177 
##       SibSp       Parch      Ticket        Fare       Cabin    Embarked 
##           0           0           0           0           0           0</code></pre>
<pre class="r"><code>colSums(train==&#39;&#39;)</code></pre>
<pre><code>## PassengerId    Survived      Pclass        Name         Sex         Age 
##           0           0           0           0           0          NA 
##       SibSp       Parch      Ticket        Fare       Cabin    Embarked 
##           0           0           0           0         687           2</code></pre>
<div id="the-age-column-and-the-cabin-column-has-the-greatest-number-of-missing-values" class="section level3">
<h3>The Age column and the Cabin column has the greatest number of missing values</h3>
</div>
<div id="i-would-expect-class-to-have-a-large-impact-on-survivability" class="section level3">
<h3>I would expect class to have a large impact on survivability</h3>
<pre class="r"><code>#Plot class vs survival
ggplot(train[1:891,], aes(x = Pclass, fill = factor(Survived))) +
  geom_bar(stat=&#39;count&#39;) +
  labs(x = &#39;Class&#39;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-4-1.png" width="672" />
###As the class went down, the fraction of people that survived went down
### I would expect the number of siblings to have a large impact on survivability</p>
<pre class="r"><code>#Plot number of siblings vs survival
ggplot(train[1:891,], aes(x = SibSp, fill = factor(Survived))) +
  geom_bar(stat=&#39;count&#39;) +
  labs(x = &#39;Siblings&#39;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-5-1.png" width="672" />
### As the number of siblings went up, the fraction of people that survived went down</p>
<pre class="r"><code>### Remove Cabin and Age because it has many missing values
titanic_data = subset(train, select =-c(Cabin, Age))

head(titanic_data)</code></pre>
<pre><code>##   PassengerId Survived Pclass
## 1           1        0      3
## 2           2        1      1
## 3           3        1      3
## 4           4        1      1
## 5           5        0      3
## 6           6        0      3
##                                                  Name    Sex SibSp Parch
## 1                             Braund, Mr. Owen Harris   male     1     0
## 2 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female     1     0
## 3                              Heikkinen, Miss. Laina female     0     0
## 4        Futrelle, Mrs. Jacques Heath (Lily May Peel) female     1     0
## 5                            Allen, Mr. William Henry   male     0     0
## 6                                    Moran, Mr. James   male     0     0
##             Ticket    Fare Embarked
## 1        A/5 21171  7.2500        S
## 2         PC 17599 71.2833        C
## 3 STON/O2. 3101282  7.9250        S
## 4           113803 53.1000        S
## 5           373450  8.0500        S
## 6           330877  8.4583        Q</code></pre>
<p>###Run the linear regression model with all the variables</p>
<pre class="r"><code>model &lt;- glm(formula = Survived~Pclass+Sex+SibSp+Parch+Fare+Embarked, data = train, family = &#39;binomial&#39;)
summary(model)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Survived ~ Pclass + Sex + SibSp + Parch + Fare + 
##     Embarked, family = &quot;binomial&quot;, data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.3636  -0.6727  -0.4596   0.6698   2.5523  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  15.208813 624.193890   0.024   0.9806    
## Pclass       -0.839111   0.130378  -6.436 1.23e-10 ***
## Sexmale      -2.729239   0.197943 -13.788  &lt; 2e-16 ***
## SibSp        -0.233804   0.101116  -2.312   0.0208 *  
## Parch        -0.072900   0.114347  -0.638   0.5238    
## Fare          0.002455   0.002369   1.036   0.3002    
## EmbarkedC   -11.710160 624.193891  -0.019   0.9850    
## EmbarkedQ   -11.914170 624.193942  -0.019   0.9848    
## EmbarkedS   -12.176063 624.193877  -0.020   0.9844    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1186.66  on 890  degrees of freedom
## Residual deviance:  812.05  on 882  degrees of freedom
## AIC: 830.05
## 
## Number of Fisher Scoring iterations: 13</code></pre>
</div>
<div id="run-an-anova-test-in-order-to-determine-the-relative-importance-of-each-variable-to-the-model.-from-the-test-we-can-identify-which-variables-are-the-most-significant-when-predicting-survivability." class="section level3">
<h3>Run an Anova Test in order to determine the relative importance of each variable to the model. From the test, we can identify which variables are the most significant when predicting survivability.</h3>
<pre class="r"><code>anova(model, test=&quot;Chisq&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model: binomial, link: logit
## 
## Response: Survived
## 
## Terms added sequentially (first to last)
## 
## 
##          Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    
## NULL                       890    1186.66              
## Pclass    1  102.254       889    1084.40 &lt; 2.2e-16 ***
## Sex       1  257.206       888     827.20 &lt; 2.2e-16 ***
## SibSp     1    7.877       887     819.32  0.005005 ** 
## Parch     1    0.207       886     819.11  0.649181    
## Fare      1    2.361       885     816.75  0.124394    
## Embarked  3    4.698       882     812.05  0.195261    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="from-the-results-of-the-anova-test-we-can-see-that-class-sex-and-number-of-siblings-are-the-most-significant-variables-when-it-comes-to-predicting-the-survivability-of-passengers.the-prz-column-represents-the-p-value-associated-with-each-of-the-predictor-variables.-because-the-p-values-for-class-sex-and-number-of-siblings-is-less-than-0.05-this-indicates-that-these-predictor-variables-have-a-statistically-significant-relationship-with-the-response-variable-survivability-in-our-model.-thus-these-are-the-variables-we-will-include-in-our-linear-regression-model." class="section level3">
<h3>From the results of the Anova Test, we can see that Class, Sex, and Number of Siblings are the most significant variables when it comes to predicting the survivability of passengers.The Pr(&gt;|z|) column represents the p-value associated with each of the predictor variables. Because the p-values for Class, Sex, and Number of Siblings is less than 0.05, this indicates that these predictor variables have a statistically significant relationship with the response variable (Survivability) in our model. Thus these are the variables we will include in our linear regression model.</h3>
<pre class="r"><code>titanic_model &lt;- glm(formula = Survived~Pclass+Sex+SibSp, data = train, family = &#39;binomial&#39;)
summary(titanic_model)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Survived ~ Pclass + Sex + SibSp, family = &quot;binomial&quot;, 
##     data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.2689  -0.6735  -0.4747   0.6189   2.5148  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  3.43357    0.30543  11.242  &lt; 2e-16 ***
## Pclass      -0.93896    0.10647  -8.819  &lt; 2e-16 ***
## Sexmale     -2.74314    0.19027 -14.417  &lt; 2e-16 ***
## SibSp       -0.24812    0.09453  -2.625  0.00867 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1186.66  on 890  degrees of freedom
## Residual deviance:  819.32  on 887  degrees of freedom
## AIC: 827.32
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre class="r"><code>titanic_results &lt;- predict(titanic_model, newdata=test, type = &quot;response&quot;)

results &lt;- data.frame(test$PassengerId, Survived = titanic_results)

results</code></pre>
<pre><code>##     test.PassengerId   Survived
## 1                892 0.10655287
## 2                893 0.59111294
## 3                894 0.23370898
## 4                895 0.10655287
## 5                896 0.59111294
## 6                897 0.10655287
## 7                898 0.64946522
## 8                899 0.19222661
## 9                900 0.64946522
## 10               901 0.06769243
## 11               902 0.10655287
## 12               903 0.43818663
## 13               904 0.90434727
## 14               905 0.19222661
## 15               906 0.90434727
## 16               907 0.78709932
## 17               908 0.23370898
## 18               909 0.10655287
## 19               910 0.59111294
## 20               911 0.64946522
## 21               912 0.37832918
## 22               913 0.10655287
## 23               914 0.92376313
## 24               915 0.43818663
## 25               916 0.90434727
## 26               917 0.08513275
## 27               918 0.92376313
## 28               919 0.10655287
## 29               920 0.43818663
## 30               921 0.06769243
## 31               922 0.19222661
## 32               923 0.15660247
## 33               924 0.59111294
## 34               925 0.59111294
## 35               926 0.37832918
## 36               927 0.10655287
## 37               928 0.64946522
## 38               929 0.64946522
## 39               930 0.10655287
## 40               931 0.10655287
## 41               932 0.10655287
## 42               933 0.43818663
## 43               934 0.10655287
## 44               935 0.82572825
## 45               936 0.90434727
## 46               937 0.10655287
## 47               938 0.43818663
## 48               939 0.10655287
## 49               940 0.92376313
## 50               941 0.64946522
## 51               942 0.37832918
## 52               943 0.23370898
## 53               944 0.74257728
## 54               945 0.85198391
## 55               946 0.23370898
## 56               947 0.04233309
## 57               948 0.10655287
## 58               949 0.10655287
## 59               950 0.08513275
## 60               951 0.92376313
## 61               952 0.10655287
## 62               953 0.23370898
## 63               954 0.10655287
## 64               955 0.64946522
## 65               956 0.32196255
## 66               957 0.82572825
## 67               958 0.64946522
## 68               959 0.43818663
## 69               960 0.43818663
## 70               961 0.90434727
## 71               962 0.64946522
## 72               963 0.10655287
## 73               964 0.64946522
## 74               965 0.43818663
## 75               966 0.92376313
## 76               967 0.43818663
## 77               968 0.10655287
## 78               969 0.88062562
## 79               970 0.23370898
## 80               971 0.64946522
## 81               972 0.08513275
## 82               973 0.37832918
## 83               974 0.43818663
## 84               975 0.10655287
## 85               976 0.23370898
## 86               977 0.08513275
## 87               978 0.64946522
## 88               979 0.64946522
## 89               980 0.64946522
## 90               981 0.19222661
## 91               982 0.59111294
## 92               983 0.10655287
## 93               984 0.90434727
## 94               985 0.10655287
## 95               986 0.43818663
## 96               987 0.10655287
## 97               988 0.90434727
## 98               989 0.10655287
## 99               990 0.64946522
## 100              991 0.10655287
## 101              992 0.90434727
## 102              993 0.19222661
## 103              994 0.10655287
## 104              995 0.10655287
## 105              996 0.59111294
## 106              997 0.10655287
## 107              998 0.10655287
## 108              999 0.10655287
## 109             1000 0.10655287
## 110             1001 0.23370898
## 111             1002 0.23370898
## 112             1003 0.64946522
## 113             1004 0.92376313
## 114             1005 0.64946522
## 115             1006 0.90434727
## 116             1007 0.08513275
## 117             1008 0.10655287
## 118             1009 0.59111294
## 119             1010 0.43818663
## 120             1011 0.78709932
## 121             1012 0.82572825
## 122             1013 0.08513275
## 123             1014 0.90434727
## 124             1015 0.10655287
## 125             1016 0.10655287
## 126             1017 0.64946522
## 127             1018 0.10655287
## 128             1019 0.53007536
## 129             1020 0.23370898
## 130             1021 0.10655287
## 131             1022 0.10655287
## 132             1023 0.43818663
## 133             1024 0.64946522
## 134             1025 0.08513275
## 135             1026 0.10655287
## 136             1027 0.10655287
## 137             1028 0.10655287
## 138             1029 0.23370898
## 139             1030 0.64946522
## 140             1031 0.08513275
## 141             1032 0.34889114
## 142             1033 0.92376313
## 143             1034 0.37832918
## 144             1035 0.23370898
## 145             1036 0.43818663
## 146             1037 0.05361555
## 147             1038 0.43818663
## 148             1039 0.10655287
## 149             1040 0.43818663
## 150             1041 0.19222661
## 151             1042 0.92376313
## 152             1043 0.10655287
## 153             1044 0.10655287
## 154             1045 0.64946522
## 155             1046 0.04233309
## 156             1047 0.10655287
## 157             1048 0.92376313
## 158             1049 0.64946522
## 159             1050 0.43818663
## 160             1051 0.64946522
## 161             1052 0.64946522
## 162             1053 0.08513275
## 163             1054 0.82572825
## 164             1055 0.10655287
## 165             1056 0.23370898
## 166             1057 0.59111294
## 167             1058 0.43818663
## 168             1059 0.06769243
## 169             1060 0.92376313
## 170             1061 0.64946522
## 171             1062 0.10655287
## 172             1063 0.10655287
## 173             1064 0.08513275
## 174             1065 0.10655287
## 175             1066 0.08513275
## 176             1067 0.82572825
## 177             1068 0.82572825
## 178             1069 0.37832918
## 179             1070 0.82572825
## 180             1071 0.92376313
## 181             1072 0.23370898
## 182             1073 0.37832918
## 183             1074 0.90434727
## 184             1075 0.10655287
## 185             1076 0.90434727
## 186             1077 0.23370898
## 187             1078 0.82572825
## 188             1079 0.06769243
## 189             1080 0.20289778
## 190             1081 0.23370898
## 191             1082 0.19222661
## 192             1083 0.43818663
## 193             1084 0.08513275
## 194             1085 0.23370898
## 195             1086 0.23370898
## 196             1087 0.10655287
## 197             1088 0.43818663
## 198             1089 0.64946522
## 199             1090 0.23370898
## 200             1091 0.64946522
## 201             1092 0.64946522
## 202             1093 0.10655287
## 203             1094 0.37832918
## 204             1095 0.78709932
## 205             1096 0.23370898
## 206             1097 0.43818663
## 207             1098 0.64946522
## 208             1099 0.23370898
## 209             1100 0.92376313
## 210             1101 0.10655287
## 211             1102 0.10655287
## 212             1103 0.10655287
## 213             1104 0.23370898
## 214             1105 0.78709932
## 215             1106 0.40714133
## 216             1107 0.43818663
## 217             1108 0.64946522
## 218             1109 0.37832918
## 219             1110 0.90434727
## 220             1111 0.10655287
## 221             1112 0.78709932
## 222             1113 0.10655287
## 223             1114 0.82572825
## 224             1115 0.10655287
## 225             1116 0.92376313
## 226             1117 0.64946522
## 227             1118 0.10655287
## 228             1119 0.64946522
## 229             1120 0.10655287
## 230             1121 0.23370898
## 231             1122 0.23370898
## 232             1123 0.92376313
## 233             1124 0.08513275
## 234             1125 0.10655287
## 235             1126 0.37832918
## 236             1127 0.10655287
## 237             1128 0.37832918
## 238             1129 0.10655287
## 239             1130 0.78709932
## 240             1131 0.90434727
## 241             1132 0.92376313
## 242             1133 0.82572825
## 243             1134 0.37832918
## 244             1135 0.10655287
## 245             1136 0.08513275
## 246             1137 0.37832918
## 247             1138 0.82572825
## 248             1139 0.19222661
## 249             1140 0.78709932
## 250             1141 0.59111294
## 251             1142 0.78709932
## 252             1143 0.10655287
## 253             1144 0.37832918
## 254             1145 0.10655287
## 255             1146 0.10655287
## 256             1147 0.10655287
## 257             1148 0.10655287
## 258             1149 0.10655287
## 259             1150 0.82572825
## 260             1151 0.10655287
## 261             1152 0.08513275
## 262             1153 0.10655287
## 263             1154 0.82572825
## 264             1155 0.59111294
## 265             1156 0.23370898
## 266             1157 0.10655287
## 267             1158 0.43818663
## 268             1159 0.10655287
## 269             1160 0.64946522
## 270             1161 0.10655287
## 271             1162 0.43818663
## 272             1163 0.10655287
## 273             1164 0.90434727
## 274             1165 0.59111294
## 275             1166 0.10655287
## 276             1167 0.78709932
## 277             1168 0.23370898
## 278             1169 0.19222661
## 279             1170 0.19222661
## 280             1171 0.23370898
## 281             1172 0.64946522
## 282             1173 0.08513275
## 283             1174 0.64946522
## 284             1175 0.59111294
## 285             1176 0.59111294
## 286             1177 0.10655287
## 287             1178 0.10655287
## 288             1179 0.37832918
## 289             1180 0.10655287
## 290             1181 0.10655287
## 291             1182 0.43818663
## 292             1183 0.64946522
## 293             1184 0.10655287
## 294             1185 0.37832918
## 295             1186 0.10655287
## 296             1187 0.10655287
## 297             1188 0.78709932
## 298             1189 0.06769243
## 299             1190 0.43818663
## 300             1191 0.10655287
## 301             1192 0.10655287
## 302             1193 0.23370898
## 303             1194 0.23370898
## 304             1195 0.10655287
## 305             1196 0.64946522
## 306             1197 0.90434727
## 307             1198 0.37832918
## 308             1199 0.10655287
## 309             1200 0.37832918
## 310             1201 0.59111294
## 311             1202 0.10655287
## 312             1203 0.10655287
## 313             1204 0.10655287
## 314             1205 0.64946522
## 315             1206 0.92376313
## 316             1207 0.64946522
## 317             1208 0.37832918
## 318             1209 0.23370898
## 319             1210 0.10655287
## 320             1211 0.15660247
## 321             1212 0.10655287
## 322             1213 0.10655287
## 323             1214 0.23370898
## 324             1215 0.43818663
## 325             1216 0.92376313
## 326             1217 0.10655287
## 327             1218 0.74257728
## 328             1219 0.43818663
## 329             1220 0.19222661
## 330             1221 0.23370898
## 331             1222 0.82572825
## 332             1223 0.43818663
## 333             1224 0.10655287
## 334             1225 0.59111294
## 335             1226 0.10655287
## 336             1227 0.43818663
## 337             1228 0.23370898
## 338             1229 0.10655287
## 339             1230 0.23370898
## 340             1231 0.10655287
## 341             1232 0.23370898
## 342             1233 0.10655287
## 343             1234 0.08513275
## 344             1235 0.92376313
## 345             1236 0.08513275
## 346             1237 0.64946522
## 347             1238 0.23370898
## 348             1239 0.64946522
## 349             1240 0.23370898
## 350             1241 0.82572825
## 351             1242 0.92376313
## 352             1243 0.23370898
## 353             1244 0.23370898
## 354             1245 0.19222661
## 355             1246 0.59111294
## 356             1247 0.43818663
## 357             1248 0.88062562
## 358             1249 0.10655287
## 359             1250 0.10655287
## 360             1251 0.59111294
## 361             1252 0.01612043
## 362             1253 0.78709932
## 363             1254 0.82572825
## 364             1255 0.10655287
## 365             1256 0.90434727
## 366             1257 0.59111294
## 367             1258 0.08513275
## 368             1259 0.64946522
## 369             1260 0.92376313
## 370             1261 0.23370898
## 371             1262 0.19222661
## 372             1263 0.92376313
## 373             1264 0.43818663
## 374             1265 0.23370898
## 375             1266 0.90434727
## 376             1267 0.92376313
## 377             1268 0.53007536
## 378             1269 0.23370898
## 379             1270 0.43818663
## 380             1271 0.04233309
## 381             1272 0.10655287
## 382             1273 0.10655287
## 383             1274 0.64946522
## 384             1275 0.59111294
## 385             1276 0.23370898
## 386             1277 0.78709932
## 387             1278 0.10655287
## 388             1279 0.23370898
## 389             1280 0.10655287
## 390             1281 0.05361555
## 391             1282 0.43818663
## 392             1283 0.92376313
## 393             1284 0.10655287
## 394             1285 0.23370898
## 395             1286 0.05361555
## 396             1287 0.90434727
## 397             1288 0.10655287
## 398             1289 0.90434727
## 399             1290 0.10655287
## 400             1291 0.10655287
## 401             1292 0.92376313
## 402             1293 0.19222661
## 403             1294 0.92376313
## 404             1295 0.43818663
## 405             1296 0.37832918
## 406             1297 0.23370898
## 407             1298 0.19222661
## 408             1299 0.37832918
## 409             1300 0.64946522
## 410             1301 0.59111294
## 411             1302 0.64946522
## 412             1303 0.90434727
## 413             1304 0.64946522
## 414             1305 0.10655287
## 415             1306 0.92376313
## 416             1307 0.10655287
## 417             1308 0.10655287
## 418             1309 0.08513275</code></pre>
</div>
